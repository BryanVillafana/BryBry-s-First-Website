<html>
<head>
<title> Ethical 1 </title>
  <meta charset="utf-8">
  <body>
<style>
@import url('https://fonts.googleapis.com/css?family=Merriweather+Sans');


body {
  font-family: 'Merriweather Sans', sans-serif;
  background-image: url("abstract-astro-astronomy-956999.jpg");
  margin: 0
}

#header {
  width: 100%;
  border-radius: 0px;
  margin-top: 0px;
  text-align: center;
  border-style: hidden;
}


div {
  width: 85%;
  margin: 0 auto;
  background-color: rgb(231, 231, 231);
  color: rgb(145, 37, 33);
  border: 1px solid gold;
  border-radius: 30px;
  margin-top: 20px;
  padding: 10px 20px;
}
</style>

<div id="header">
<h1> Ethical Reflection 1</h1>

</div>

<div>
<h1 align="center"> Machine Bias</h1>
    <p> In courtrooms throughout the country risk assessments are being done to determine the chance of an offender to commit another crime in the future. These risk assessments are done by computer programs and the most common program used is C.O.M.P.A.S. This program was made by a for-profit company named Northpointe. The issue with the program is its accuracy and the factors that will influence accuracy. One of these factors may be race, which means the program might have a biased towards people of color.
<p>An example of this would be the story of Brisha Borden. Brisha was going to pick up her god-sister from school, she was running late and saw a blue huffy bike and a razor scooter. Each of these items belonged to a 6 year old boy. Brisha and a friend of hers took the bike and scooter but realized they were too small and were on their way to return the items. A neighbor witnessed this and called the police. Brisha’s risk score was an 8 out of 10. Comparing this to another situation where a man named vernon porter stole $86 worth of tools from a home depot. Vernon also has a criminal history. He was arrested before on two armed robbery charges and attempted armed robbery. Vernon’s risk score was a 3/10. Vernon then stole thousands of dollars worth of electronics after his risk assessment. Vernon, being a white man received a score lower than what it should have been- and Brisha, being black, recieved a higher score.
  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing>" >(Machine Bias by Pro Publica)</a>.</p>
<p>More cases like this are occurring throughout the justice system and the sentencing commission was asked to perform a study on these scores and machine bias. The commission still hasn’t investigated risk scores.<a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing>" >(Machine Bias by Pro Publica)</a>Investigations by other journals have shown that scores were extremely unreliable for violent crimes and were about 50% accurate when it came to assessing things like misdemeanors. Black people were labelled at higher risk for both of these.</p>
<p>I believe the issue does not entirely lie in the score itself, but how judges use the assessment to determine almost everything. Judges are raising sentences based on the defendants risk score, changing probation and rehabilitation programs based on the scores and raising bonds based on them. The scores were only meant to estimate the success someone will have through probation, not to determine sentencing. Wisconsin uses these scores every step of the legal process without prior validation testing. Judges were trained and their job is to judge and determine for themselves what to do with an offender. These scores only reveal a small piece of the defendant, it does not take into account living situations or the crime itself. That part is up to the judge and I find it extremely unjust to send someone to prison for something they might do.</p>
 </p>
</div>
  </body>
